

<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="">
    
    
      
        <title>Defining optimization pipelines in Kenning - Kenning</title>
      
    
    
      
        
        
      
      

    
    
    
      
        
        
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
        <link rel="stylesheet" type="text/css" href="_static/sphinx_immaterial_theme.c5589c0bd87d933a4.min.css?v=eeeb54bc" />
        <link rel="stylesheet" type="text/css" href="_static/css/bokeh.css?v=8bee089c" />
        <link rel="stylesheet" type="text/css" href="_static/css/compatibility.css?v=5eb45fba" />
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="deep-orange">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Kenning" class="md-header__button md-logo" aria-label="Kenning" data-md-component="logo">
      <img src="_static/white.svg" alt="logo">
    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Kenning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Defining optimization pipelines in Kenning
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="deep-orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <div class="md-header__button">
        <a href="kenning.pdf" title="PDF - kenning.pdf">
          <div class="md-icon">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M64 0C28.7 0 0 28.7 0 64v384c0 35.3 28.7 64 64 64h256c35.3 0 64-28.7 64-64V160H256c-17.7 0-32-14.3-32-32V0H64zm192 0v128h128L256 0zM64 224h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V240c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V240zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V240c0-8.8 7.2-16 16-16z"/></svg>
          </div>
        </a>
      </div>
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/antmicro/kenning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    antmicro/kenning
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Kenning" class="md-nav__button md-logo" aria-label="Kenning" data-md-component="logo">
      <img src="_static/white.svg" alt="logo">
    </a>
    Kenning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/antmicro/kenning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    antmicro/kenning
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="introduction.html" class="md-nav__link">
        <span class="md-ellipsis">Introduction</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="project-readme.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="dl-deployment-stack.html" class="md-nav__link">
        <span class="md-ellipsis">Deep Learning deployment stack</span>
      </a>
    </li>
  

    
      
      
      

  
  
    
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          <span class="md-ellipsis">Defining optimization pipelines in Kenning</span>
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="#" class="md-nav__link md-nav__link--active">
        <span class="md-ellipsis">Defining optimization pipelines in Kenning</span>
      </a>
      
        

<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#json-specification" class="md-nav__link">
    <span class="md-ellipsis">JSON specification</span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-evaluation-using-its-native-framework" class="md-nav__link">
    <span class="md-ellipsis">Model evaluation using its native framework</span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-training" class="md-nav__link">
    <span class="md-ellipsis">Model training</span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimizing-and-running-a-model-on-a-single-device" class="md-nav__link">
    <span class="md-ellipsis">Optimizing and running a model on a single device</span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#compiling-a-model-and-running-it-remotely" class="md-nav__link">
    <span class="md-ellipsis">Compiling a model and running it remotely</span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="cmd-usage.html" class="md-nav__link">
        <span class="md-ellipsis">Using Kenning via command line arguments</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-gallery.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning gallery of use cases</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-variables.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning environment variables</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-measurements.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning measurements</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="pipeline-optimizer.html" class="md-nav__link">
        <span class="md-ellipsis">Choosing optimal optimization pipeline</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="sample-report.html" class="md-nav__link">
        <span class="md-ellipsis">Sample autogenerated report</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="sample-automl-report.html" class="md-nav__link">
        <span class="md-ellipsis">Sample Auto<wbr>ML report</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-flow.html" class="md-nav__link">
        <span class="md-ellipsis">Creating applications with Kenning</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-development.html" class="md-nav__link">
        <span class="md-ellipsis">Developing Kenning blocks</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-resources.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning resources</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-protocols.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning protocols</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-platforms.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning platforms</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-api.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning API</span>
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset" role="main">
                  


  <a href="https://github.com/antmicro/kenning/blob/main/docs/source/json-scenarios.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>

<h1 id="defining-optimization-pipelines-in-kenning">Defining optimization pipelines in Kenning<a class="headerlink" href="#defining-optimization-pipelines-in-kenning" title="Link to this heading">¶</a></h1>
<p>Kenning blocks (specified in the <a class="reference internal" href="kenning-api.html"><span class="doc std std-doc">Kenning API</span></a>) can be configured either via command line (see <a class="reference internal" href="cmd-usage.html"><span class="doc std std-doc">Using Kenning via command line arguments</span></a>), or via configuration files, specified in JSON format.
The latter approach allows the user to create more advanced and easy-to-reproduce scenarios for model deployment.
Most notably, various optimizers available through Kenning can be chained to utilize various optimizations and get better performing models.</p>
<p>One of the scenarios most commonly used in Kenning is model optimization and compilation.
It can be done using <code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_tester</span></code>.</p>
<p>To run below examples it is required to install Kenning with dependencies as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;kenning[tensorflow,tflite,tvm] @ git+https://github.com/antmicro/kenning.git&quot;</span>
</code></pre></div>
</div>
<h2 id="json-specification">JSON specification<a class="headerlink" href="#json-specification" title="Link to this heading">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_tester</span></code> takes the specification of optimization and the testing flow in a JSON format.
The root element of the JSON file is a dictionary that can have the following keys:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">model_wrapper</span></code> - <strong>mandatory field</strong>, accepts dictionary as a value that defines the <a class="reference internal" href="kenning-api.html#modelwrapper-api"><span class="std std-ref">ModelWrapper</span></a> object for the deployed model (provides I/O processing, optionally model).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataset</span></code> - <strong>mandatory field</strong>, accepts dictionary as a value that defines the <a class="reference internal" href="kenning-api.html#dataset-api"><span class="std std-ref">Dataset</span></a> object for model optimization and evaluation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizers</span></code> - <em>optional field</em>, accepts a list of dictionaries specifying the sequence of <a class="reference internal" href="kenning-api.html#optimizer-api"><span class="std std-ref">Optimizer</span></a>-based optimizations applied to the model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">protocol</span></code> - <em>optional field</em>, defines the <a class="reference internal" href="kenning-api.html#protocol-api"><span class="std std-ref">Protocol</span></a> object used to communicate with a remote target platform.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">runtime</span></code> - <em>optional field</em> (<strong>required</strong> when <code class="docutils literal notranslate"><span class="pre">optimizers</span></code> are provided), defines the <a class="reference internal" href="kenning-api.html#runtime-api"><span class="std std-ref">Runtime</span></a>-based object that will infer the model on target device.</p></li>
</ul>
<p>Each dictionary in the fields above consists of:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - appropriate class for the key,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">parameters</span></code> - <code class="docutils literal notranslate"><span class="pre">type</span></code>-specific arguments for an underlying class (see <a class="reference internal" href="kenning-development.html#defining-arguments-for-core-classes"><span class="std std-ref">Defining arguments for core classes</span></a>).</p></li>
</ul>
<h2 id="model-evaluation-using-its-native-framework">Model evaluation using its native framework<a class="headerlink" href="#model-evaluation-using-its-native-framework" title="Link to this heading">¶</a></h2>
<p>The simplest JSON configuration looks as follows:</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption highlight"><span class="filename"><span class="caption-number">Listing 1 </span><span class="caption-text">
</span>mobilenetv2-tensorflow-native.json<a class="headerlink" href="#id1" title="Permalink to this code">¶</a></span></div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_wrapper&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.modelwrappers.classification.tensorflow_pet_dataset.TensorFlowPetDatasetMobileNetV2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;native&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning:///models/classification/tensorflow_pet_dataset_mobilenetv2.h5&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;batch_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;learning_rate&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0001</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;num_epochs&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">50</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;logdir&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;build/logs&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;dataset&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.datasets.pet_dataset.PetDataset&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;dataset_root&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/PetDataset&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
</div>
</div>
<p>It only takes <code class="docutils literal notranslate"><span class="pre">model_wrapper</span></code> and <code class="docutils literal notranslate"><span class="pre">dataset</span></code>.
This way, the model will be loaded and evaluated using its native framework.</p>
<p>The <a class="reference internal" href="kenning-api.html#modelwrapper-api"><span class="std std-ref">ModelWrapper</span></a> used is <code class="docutils literal notranslate"><span class="pre">TensorFlowPetDatasetMobileNetV2</span></code>, which is a MobileNetV2 model trained to classify 37 breeds of cats and dogs.
In the <code class="docutils literal notranslate"><span class="pre">type</span></code> field, we specify the full “path” to the class by specifying the module it is implemented in (<code class="docutils literal notranslate"><span class="pre">kenning.modelwrappers.classification.tensorflow_pet_dataset</span></code>) and the name of the class (<code class="docutils literal notranslate"><span class="pre">TensorFlowPetDatasetMobileNetV2</span></code>) in a Python-like format (dot-separated).</p>
<p>In <code class="docutils literal notranslate"><span class="pre">parameters</span></code>, arguments specific to <code class="docutils literal notranslate"><span class="pre">TensorFlowPetDatasetMobileNetV2</span></code> are provided.
The following parameters are available based on the argument specification:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span class="c1"># this argument structure is taken from kenning.core.model - it is inherited by child classes</span>
<span class="n">arguments_structure</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;modelpath&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;argparse_name&#39;</span><span class="p">:</span> <span class="s1">&#39;--model-path&#39;</span><span class="p">,</span>
        <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Path to the model&#39;</span><span class="p">,</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span>
        <span class="s1">&#39;required&#39;</span><span class="p">:</span> <span class="kc">True</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
</div>
<p>The only mandatory parameter here is <code class="docutils literal notranslate"><span class="pre">model_path</span></code>, which points to a file containing the model.
It is a required argument.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">dataset</span></code> used here, is <code class="docutils literal notranslate"><span class="pre">PetDataset</span></code>. Like previously, it is provided in a module-like format (<code class="docutils literal notranslate"><span class="pre">kenning.datasets.pet_dataset.PetDataset</span></code>). The parameters here are specified in <code class="docutils literal notranslate"><span class="pre">kenning.core.dataset.Dataset</span></code> (inherited) and <code class="docutils literal notranslate"><span class="pre">kenning.core.dataset.PetDataset</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span class="n">arguments_structure</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># coming from kenning.core.dataset.Dataset</span>
    <span class="s1">&#39;root&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;argparse_name&#39;</span><span class="p">:</span> <span class="s1">&#39;--dataset-root&#39;</span><span class="p">,</span>
        <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Path to the dataset directory&#39;</span><span class="p">,</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">Path</span><span class="p">,</span>
        <span class="s1">&#39;required&#39;</span><span class="p">:</span> <span class="kc">True</span>
    <span class="p">},</span>
    <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;argparse_name&#39;</span><span class="p">:</span> <span class="s1">&#39;--inference-batch-size&#39;</span><span class="p">,</span>
        <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;The batch size for providing the input data&#39;</span><span class="p">,</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="s1">&#39;default&#39;</span><span class="p">:</span> <span class="mi">1</span>
    <span class="p">},</span>
    <span class="s1">&#39;download_dataset&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Downloads the dataset before taking any action&#39;</span><span class="p">,</span>
        <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="s1">&#39;default&#39;</span><span class="p">:</span> <span class="kc">False</span>
    <span class="p">},</span>
    <span class="c1"># coming from kenning.datasets.pet_dataset.PetDataset</span>
    <span class="s1">&#39;classify_by&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;argparse_name&#39;</span><span class="p">:</span> <span class="s1">&#39;--classify-by&#39;</span><span class="p">,</span>
        <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Determines if classification should be performed by species or by breeds&#39;</span><span class="p">,</span>
        <span class="s1">&#39;default&#39;</span><span class="p">:</span> <span class="s1">&#39;breeds&#39;</span><span class="p">,</span>
        <span class="s1">&#39;enum&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;species&#39;</span><span class="p">,</span> <span class="s1">&#39;breeds&#39;</span><span class="p">]</span>
    <span class="p">},</span>
    <span class="s1">&#39;image_memory_layout&#39;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s1">&#39;argparse_name&#39;</span><span class="p">:</span> <span class="s1">&#39;--image-memory-layout&#39;</span><span class="p">,</span>
        <span class="s1">&#39;description&#39;</span><span class="p">:</span> <span class="s1">&#39;Determines if images should be delivered in NHWC or NCHW format&#39;</span><span class="p">,</span>
        <span class="s1">&#39;default&#39;</span><span class="p">:</span> <span class="s1">&#39;NHWC&#39;</span><span class="p">,</span>
        <span class="s1">&#39;enum&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;NHWC&#39;</span><span class="p">,</span> <span class="s1">&#39;NCHW&#39;</span><span class="p">]</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
</div>
<p>As visible, the parameters allow the user to:</p>
<ul class="simple">
<li><p>specify the dataset’s location,</p></li>
<li><p>download the dataset,</p></li>
<li><p>configure data layout and batch size,</p></li>
<li><p>configure anything specific to the dataset.</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title">Note</p>
<p>For more details on defining parameters for Kenning core classes, check <a class="reference internal" href="kenning-development.html#defining-arguments-for-core-classes"><span class="std std-ref">Defining arguments for core classes</span></a>.</p>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">optimizers</span></code> or <code class="docutils literal notranslate"><span class="pre">runtime</span></code> are not specified, the model is executed using the <a class="reference internal" href="kenning-api.html#modelwrapper-api"><span class="std std-ref">ModelWrapper</span></a>‘s <code class="docutils literal notranslate"><span class="pre">run_inference</span></code> method.
The dataset test data is passed through the model and evaluation metrics are collected.</p>
<p>To run the defined pipeline (assuming that the JSON file is under <code class="docutils literal notranslate"><span class="pre">pipeline.json</span></code>), run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--json-cfg<span class="w"> </span>mobilenetv2-tensorflow-native.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--measurements<span class="w"> </span>measurements.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--verbosity<span class="w"> </span>INFO
</code></pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">measurements.json</span></code> file is the output of the <code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_tester</span></code> providing measurement data.
It contains information such as:</p>
<ul class="simple">
<li><p>the JSON configuration defined above,</p></li>
<li><p>versions of core class packages used (e.g. <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code>, <code class="docutils literal notranslate"><span class="pre">torch</span></code>, <code class="docutils literal notranslate"><span class="pre">tvm</span></code>),</p></li>
<li><p>available resource usage readings (CPU usage, GPU usage, memory usage),</p></li>
<li><p>data necessary for evaluation, such as predictions, confusion matrix, etc.</p></li>
</ul>
<p>This information can be later used for <a class="reference internal" href="cmd-usage.html#report-generation"><span class="std std-ref">Generating performance reports</span></a>.</p>
<div class="note admonition">
<p class="admonition-title">Note</p>
<p>Check <a class="reference internal" href="kenning-measurements.html"><span class="doc">Kenning measurements</span></a> for more information.</p>
</div>
<h2 id="model-training">Model training<a class="headerlink" href="#model-training" title="Link to this heading">¶</a></h2>
<p>Provided that training is supported by a given model, you can specify parameters as follows:</p>
<div class="literal-block-wrapper docutils container" id="id2">
<div class="code-block-caption highlight"><span class="filename"><span class="caption-number">Listing 2 </span><span class="caption-text">
</span>mobilenetv2-tensorflow-native.json<a class="headerlink" href="#id2" title="Permalink to this code">¶</a></span></div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_wrapper&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.modelwrappers.classification.tensorflow_pet_dataset.TensorFlowPetDatasetMobileNetV2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;native&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning:///models/classification/tensorflow_pet_dataset_mobilenetv2.h5&quot;</span><span class="p">,</span>
<span class="hll"><span class="w">      </span><span class="nt">&quot;batch_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
</span><span class="hll"><span class="w">      </span><span class="nt">&quot;learning_rate&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0001</span><span class="p">,</span>
</span><span class="hll"><span class="w">      </span><span class="nt">&quot;num_epochs&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">50</span><span class="p">,</span>
</span><span class="hll"><span class="w">      </span><span class="nt">&quot;logdir&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;build/logs&quot;</span>
</span><span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;dataset&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.datasets.pet_dataset.PetDataset&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;dataset_root&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/PetDataset&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
</div>
</div>
<p>To train the model, simply run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>train<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--json-cfg<span class="w"> </span>mobilenetv2-tensorflow-native.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--verbosity<span class="w"> </span>INFO
</code></pre></div>
</div>
<p>Furthermore, the configuration is shared among subcommands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>train<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--json-cfg<span class="w"> </span>train-test.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--measurements<span class="w"> </span>output.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--verbosity<span class="w"> </span>INFO
</code></pre></div>
</div>
<p>File with measurements also stores training information, which can be viewed directly or displayed in a generated report.</p>
<h2 id="optimizing-and-running-a-model-on-a-single-device">Optimizing and running a model on a single device<a class="headerlink" href="#optimizing-and-running-a-model-on-a-single-device" title="Link to this heading">¶</a></h2>
<p>Model optimization and deployment can be performed directly on target device, if the device is able to perform the optimization steps.
It can also be used to check the outcome of certain optimizations on a desktop platform before deployment.</p>
<p>Optimizations and compilers used in a scenario are defined in the <code class="docutils literal notranslate"><span class="pre">optimizers</span></code> field.
This field accepts a list of optimizers - they are applied to the model in the same order in which they are defined in the <code class="docutils literal notranslate"><span class="pre">optimizers</span></code> field.</p>
<p>For example, a model can be subjected to the following optimizations:</p>
<ul class="simple">
<li><p>Quantization of weights and activations using TensorFlow Lite.</p></li>
<li><p>Conversion of data layout from NHWC to NCHW format using Apache TVM</p></li>
<li><p>Compilation to x86 runtime with AVX2 vector extensions using Apache TVM.</p></li>
</ul>
<p>Such case will result is the following scenario:</p>
<div class="literal-block-wrapper docutils container" id="id3">
<div class="code-block-caption highlight"><span class="filename"><span class="caption-number">Listing 3 </span><span class="caption-text">
</span>mobilenetv2-tensorflow-tvm-avx-int8.json<a class="headerlink" href="#id3" title="Permalink to this code">¶</a></span></div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_wrapper&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.modelwrappers.classification.tensorflow_pet_dataset.TensorFlowPetDatasetMobileNetV2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tvm-avx2-int8&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning:///models/classification/tensorflow_pet_dataset_mobilenetv2.h5&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;dataset&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.datasets.pet_dataset.PetDataset&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;dataset_root&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/PetDataset&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="hll"><span class="w">  </span><span class="nt">&quot;optimizers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
</span><span class="hll"><span class="w">    </span><span class="p">{</span>
</span><span class="hll"><span class="w">      </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.optimizers.tflite.TFLiteCompiler&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="w">      </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">        </span><span class="nt">&quot;target&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int8&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="w">        </span><span class="nt">&quot;compiled_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/int8.tflite&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="w">        </span><span class="nt">&quot;inference_input_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int8&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="w">        </span><span class="nt">&quot;inference_output_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int8&quot;</span>
</span><span class="hll"><span class="w">      </span><span class="p">}</span>
</span><span class="hll"><span class="w">    </span><span class="p">},</span>
</span><span class="hll"><span class="w">    </span><span class="p">{</span>
</span><span class="hll"><span class="w">      </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.optimizers.tvm.TVMCompiler&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="w">      </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">        </span><span class="nt">&quot;target&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llvm -mcpu=core-avx2&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="w">        </span><span class="nt">&quot;opt_level&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
</span><span class="hll"><span class="w">        </span><span class="nt">&quot;conv2d_data_layout&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;NCHW&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="w">        </span><span class="nt">&quot;compiled_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/int8_tvm.tar&quot;</span>
</span><span class="hll"><span class="w">      </span><span class="p">}</span>
</span><span class="hll"><span class="w">    </span><span class="p">}</span>
</span><span class="hll"><span class="w">  </span><span class="p">],</span>
</span><span class="hll"><span class="w">  </span><span class="nt">&quot;runtime&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.runtimes.tvm.TVMRuntime&quot;</span><span class="p">,</span>
</span><span class="hll"><span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">      </span><span class="nt">&quot;save_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/int8_tvm.tar&quot;</span>
</span><span class="hll"><span class="w">    </span><span class="p">}</span>
</span><span class="hll"><span class="w">  </span><span class="p">}</span>
</span><span class="p">}</span>
</code></pre></div>
</div>
</div>
<p>As emphasized above, the <code class="docutils literal notranslate"><span class="pre">optimizers</span></code> list is added, with two entries:</p>
<ul class="simple">
<li><p>a <code class="docutils literal notranslate"><span class="pre">kenning.optimizers.tflite.TFLiteCompiler</span></code> type block, quantizing the model,</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">kenning.optimizers.tvm.TVMCompiler</span></code> type block, performing remaining optimization steps.</p></li>
</ul>
<p>In the <code class="docutils literal notranslate"><span class="pre">runtime</span></code> field, a TVM-specific <code class="docutils literal notranslate"><span class="pre">kenning.runtimes.tvm.TVMRuntime</span></code> type is used.</p>
<p>The first optimizer on the list reads the input model path from the <a class="reference internal" href="kenning-api.html#modelwrapper-api"><span class="std std-ref">ModelWrapper</span></a>‘s <code class="docutils literal notranslate"><span class="pre">model_path</span></code> field.
Each consecutive <a class="reference internal" href="kenning-api.html#optimizer-api"><span class="std std-ref">Optimizer</span></a> reads the model from a file saved by the previous <a class="reference internal" href="kenning-api.html#optimizer-api"><span class="std std-ref">Optimizer</span></a>.
In the simplest scenario, the model is saved to <code class="docutils literal notranslate"><span class="pre">compiled_model_path</span></code> in each optimizer, and is fetched by the next <a class="reference internal" href="kenning-api.html#optimizer-api"><span class="std std-ref">Optimizer</span></a>.</p>
<p>In case the default output file type of the previous <a class="reference internal" href="kenning-api.html#optimizer-api"><span class="std std-ref">Optimizer</span></a> is not supported by the next <a class="reference internal" href="kenning-api.html#optimizer-api"><span class="std std-ref">Optimizer</span></a>, the first common supported model format is determined and used to pass the model between optimizers.</p>
<p>In case no such format exists, the <code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_tester</span></code> returns an error.</p>
<div class="note admonition">
<p class="admonition-title">Note</p>
<p>More details on input/output formats between <a class="reference internal" href="kenning-api.html#optimizer-api"><span class="std std-ref">Optimizer</span></a> objects can be found in <a class="reference internal" href="kenning-development.html"><span class="doc std std-doc">Developing Kenning blocks</span></a>.</p>
</div>
<p>The scenario can be executed as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>optimize<span class="w"> </span><span class="nb">test</span><span class="w"> </span>--json-cfg<span class="w"> </span>mobilenetv2-tensorflow-tvm-avx-int8.json<span class="w"> </span>--measurements<span class="w"> </span>output.json
</code></pre></div>
</div>
<h2 id="compiling-a-model-and-running-it-remotely">Compiling a model and running it remotely<a class="headerlink" href="#compiling-a-model-and-running-it-remotely" title="Link to this heading">¶</a></h2>
<p>For some platforms, we cannot run a Python script to evaluate or run the model to check its quality - the dataset is too large to fit in the storage, no libraries or compilation tools are available for the target platform, or the device does not have an operating system to run Python on.</p>
<p>In such cases, it is possible to evaluate the system remotely using the <a class="reference internal" href="kenning-api.html#protocol-api"><span class="std std-ref">Protocol</span></a> and the <code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_server</span></code> scenario.</p>
<p>For this use case, we need two JSON files - one for inference server configuration, and another one for the <code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_tester</span></code> configuration, which acts as a runtime client.</p>
<p>The client and the server may communicate via different means, protocols and interfaces - we can use TCP communication, UART communication or other.
It depends on the <a class="reference internal" href="kenning-api.html#protocol-api"><span class="std std-ref">Protocol</span></a> used.</p>
<p>In addition, in such scenario optimizers can be executed either on host (which is default behavior) or on target device.
To specify it, you can use <code class="docutils literal notranslate"><span class="pre">location</span></code> parameter of the <a class="reference internal" href="kenning-api.html#optimizer-api"><span class="std std-ref">Optimizer</span></a>.</p>
<p>To create client/server scenario configuration it is required to add a <code class="docutils literal notranslate"><span class="pre">protocol</span></code> entry:</p>
<div class="literal-block-wrapper docutils container" id="id4">
<div class="code-block-caption highlight"><span class="filename"><span class="caption-number">Listing 4 </span><span class="caption-text">
</span>tflite-tvm-classification-client-server.json<a class="headerlink" href="#id4" title="Permalink to this code">¶</a></span></div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;platform&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;LocalPlatform&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;model_wrapper&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;TensorFlowPetDatasetMobileNetV2&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning:///models/classification/tensorflow_pet_dataset_mobilenetv2.h5&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;dataset&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;PetDataset&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;dataset_root&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/PetDataset&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="nt">&quot;optimizers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;TFLiteCompiler&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;target&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;default&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;compiled_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/compiled_tflite.tflite&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;inference_input_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;float32&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;inference_output_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;float32&quot;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;TVMCompiler&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;target&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llvm -mcpu=core-avx2&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;compiled_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/compiled_tvm.tar&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;opt_level&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;location&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;target&quot;</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;runtime&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;TVMRuntime&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;save_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/compiled_model.tar&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="hll"><span class="w">    </span><span class="nt">&quot;protocol&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
</span><span class="hll"><span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;NetworkProtocol&quot;</span>
</span><span class="hll"><span class="w">    </span><span class="p">}</span>
</span><span class="p">}</span>
</code></pre></div>
</div>
</div>
<p>In the <code class="docutils literal notranslate"><span class="pre">protocol</span></code> entry, we specify a <code class="docutils literal notranslate"><span class="pre">kenning.protocols.network.NetworkProtocol</span></code> and provide a server address (<code class="docutils literal notranslate"><span class="pre">host</span></code>), an application port (<code class="docutils literal notranslate"><span class="pre">port</span></code>) and packet size (<code class="docutils literal notranslate"><span class="pre">packet_size</span></code>)</p>
<p>The server parses only <code class="docutils literal notranslate"><span class="pre">runtime</span></code> and <code class="docutils literal notranslate"><span class="pre">protocol</span></code> from the configuration, so any changes to the other of the blocks does not require server restart.
The server uses <code class="docutils literal notranslate"><span class="pre">protocol</span></code> to receive requests from clients and <code class="docutils literal notranslate"><span class="pre">runtime</span></code> to run the tested models.</p>
<p>The remaining things are provided by the client - input data and model.
Direct outputs from the model are sent as is to the client, so it can postprocess them and evaluate the model using the dataset.
The server also sends measurements from its sensors in JSON format as long as it is able to collect and send them.</p>
<p>First, run the server, so that it is available for the client:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>server<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--json-cfg<span class="w"> </span>tflite-tvm-classification-client-server.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--verbosity<span class="w"> </span>INFO<span class="w"> </span><span class="p">&amp;</span>
</code></pre></div>
</div>
<p>Then, run the client:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>optimize<span class="w"> </span><span class="nb">test</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--json-cfg<span class="w"> </span>tflite-tvm-classification-client-server.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--measurements<span class="w"> </span>./build/tflite-tvm-classification.json<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--verbosity<span class="w"> </span>INFO
</code></pre></div>
</div>
<p>The rest of the flow is automated.</p>
<p>To execute one of the optimizers on the target-side, simply add the <code class="docutils literal notranslate"><span class="pre">location</span></code> parameter as follows:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><code><span class="nt">&quot;optimizers&quot;</span><span class="p">:</span>
<span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.optimizers.tflite.TFLiteCompiler&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;target&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int8&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;compiled_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/int8.tflite&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;inference_input_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int8&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;inference_output_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int8&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.optimizers.tvm.TVMCompiler&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;target&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llvm -mcpu=core-avx2&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;opt_level&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;conv2d_data_layout&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;NCHW&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;compiled_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/int8_tvm.tar&quot;</span><span class="p">,</span>
<span class="hll"><span class="w">            </span><span class="nt">&quot;location&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;target&quot;</span>
</span><span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">],</span>
</code></pre></div>
</div>
<p>and start the client the same as above (it is not required to restart server).</p>


  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      2026-02-12
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="dl-deployment-stack.html" class="md-footer__link md-footer__link--prev" aria-label="Previous: Deep Learning deployment stack" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Deep Learning deployment stack
            </div>
          </div>
        </a>
      
      
        
        <a href="cmd-usage.html" class="md-footer__link md-footer__link--next" aria-label="Next: Using Kenning via command line arguments" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Using Kenning via command line arguments
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  
  
  <div class="md-footer-meta md-typeset">
    
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-footer-copyright__highlight">
        Copyright &#169; 2020-2025, Antmicro.
        
    </div>
  
      <a href="https://github.com/antmicro/kenning/tree/f85992e2278041c41303b1c402b144427c0f2a97">f85992e2</a>
        @ <a href="https://github.com/antmicro/kenning/tree/main">main</a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://github.com/antmicro" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://twitter.com/antmicro" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
</div>
      
    </div>
    
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": ".", "features": ["toc.integrate"], "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
      
        <script src="_static/sphinx_immaterial_theme.f9d9eeeb247ace16c.min.js?v=8ec58cb5"></script>
    
  </body>
</html>