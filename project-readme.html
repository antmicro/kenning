

<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="">
    
    
      
        <title>Kenning - Kenning</title>
      
    
    
      
        
        
      
      

    
    
    
      
        
        
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
        <link rel="stylesheet" type="text/css" href="_static/sphinx_immaterial_theme.c5589c0bd87d933a4.min.css?v=eeeb54bc" />
        <link rel="stylesheet" type="text/css" href="_static/css/bokeh.css?v=8bee089c" />
        <link rel="stylesheet" type="text/css" href="_static/css/compatibility.css?v=5eb45fba" />
    <script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="deep-orange">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="index.html" title="Kenning" class="md-header__button md-logo" aria-label="Kenning" data-md-component="logo">
      <img src="_static/white.svg" alt="logo">
    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Kenning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Kenning
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="deep-orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="deep-orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <div class="md-header__button">
        <a href="kenning.pdf" title="PDF - kenning.pdf">
          <div class="md-icon">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M64 0C28.7 0 0 28.7 0 64v384c0 35.3 28.7 64 64 64h256c35.3 0 64-28.7 64-64V160H256c-17.7 0-32-14.3-32-32V0H64zm192 0v128h128L256 0zM64 224h24c30.9 0 56 25.1 56 56s-25.1 56-56 56h-8v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V240c0-8.8 7.2-16 16-16zm24 80c13.3 0 24-10.7 24-24s-10.7-24-24-24h-8v48h8zm72-64c0-8.8 7.2-16 16-16h24c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48h-24c-8.8 0-16-7.2-16-16V240zm32 112h8c8.8 0 16-7.2 16-16v-64c0-8.8-7.2-16-16-16h-8v96zm96-128h48c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16h-32v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V240c0-8.8 7.2-16 16-16z"/></svg>
          </div>
        </a>
      </div>
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/antmicro/kenning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    antmicro/kenning
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="index.html" title="Kenning" class="md-nav__button md-logo" aria-label="Kenning" data-md-component="logo">
      <img src="_static/white.svg" alt="logo">
    </a>
    Kenning
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/antmicro/kenning" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    antmicro/kenning
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="introduction.html" class="md-nav__link">
        <span class="md-ellipsis">Introduction</span>
      </a>
    </li>
  

    
      
      
      

  
  
    
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          <span class="md-ellipsis">Kenning</span>
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="#" class="md-nav__link md-nav__link--active">
        <span class="md-ellipsis">Kenning</span>
      </a>
      
        

<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">Introduction</span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kenning-installation" class="md-nav__link">
    <span class="md-ellipsis">Kenning installation</span>
  </a>
  
    <nav class="md-nav" aria-label="Kenning installation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#module-installation-with-pip" class="md-nav__link">
    <span class="md-ellipsis">Module installation with pip</span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#working-directly-with-the-repository" class="md-nav__link">
    <span class="md-ellipsis">Working directly with the repository</span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kenning-structure" class="md-nav__link">
    <span class="md-ellipsis">Kenning structure</span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kenning-usage" class="md-nav__link">
    <span class="md-ellipsis">Kenning usage</span>
  </a>
  
    <nav class="md-nav" aria-label="Kenning usage">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#running-kenning" class="md-nav__link">
    <span class="md-ellipsis">Running Kenning</span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kenning-tutorials" class="md-nav__link">
    <span class="md-ellipsis">Kenning tutorials</span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-kenning-as-a-library-in-python-scripts" class="md-nav__link">
    <span class="md-ellipsis">Using Kenning as a library in Python scripts</span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#adding-new-implementations" class="md-nav__link">
    <span class="md-ellipsis">Adding new implementations</span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="dl-deployment-stack.html" class="md-nav__link">
        <span class="md-ellipsis">Deep Learning deployment stack</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="json-scenarios.html" class="md-nav__link">
        <span class="md-ellipsis">Defining optimization pipelines in Kenning</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="cmd-usage.html" class="md-nav__link">
        <span class="md-ellipsis">Using Kenning via command line arguments</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-gallery.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning gallery of use cases</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-variables.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning environment variables</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-measurements.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning measurements</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="pipeline-optimizer.html" class="md-nav__link">
        <span class="md-ellipsis">Choosing optimal optimization pipeline</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="sample-report.html" class="md-nav__link">
        <span class="md-ellipsis">Sample autogenerated report</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="sample-automl-report.html" class="md-nav__link">
        <span class="md-ellipsis">Sample Auto<wbr>ML report</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-flow.html" class="md-nav__link">
        <span class="md-ellipsis">Creating applications with Kenning</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-development.html" class="md-nav__link">
        <span class="md-ellipsis">Developing Kenning blocks</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-resources.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning resources</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-protocols.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning protocols</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-platforms.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning platforms</span>
      </a>
    </li>
  

    
      
      
      

  
  
  
  
    <li class="md-nav__item">
      <a href="kenning-api.html" class="md-nav__link">
        <span class="md-ellipsis">Kenning API</span>
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset" role="main">
                  


  <a href="https://github.com/antmicro/kenning/blob/main/docs/source/project-readme.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>

<h1 id="kenning">Kenning<a class="headerlink" href="#kenning" title="Link to this heading">¶</a></h1>
<p>Copyright (c) 2020-2025 <a class="reference external" href="https://www.antmicro.com">Antmicro</a></p>
<p><img alt="Kenning" src="_images/kenninglogo.png" /></p>
<p>Kenning is a framework for creating deployment flows and runtimes for Deep Neural Network applications on various target hardware.</p>
<p><a class="reference external" href="https://antmicro.github.io/kenning/">Kenning documentation</a> | <a class="reference external" href="https://antmicro.github.io/kenning/kenning-api.html">Core API</a> | <a class="reference external" href="https://opensource.antmicro.com/projects/kenning">kenning.ai</a> | <a class="reference external" href="https://antmicro.github.io/kenning/kenning-gallery.html">Tutorials</a>
<img alt="" src="_images/report-mosaic.png" /></p>
<p>Contents:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#introduction">Introduction</a></p></li>
<li><p><a class="reference internal" href="#kenning-installation">Kenning installation</a></p></li>
<li><p><a class="reference internal" href="#kenning-structure">Kenning structure</a></p></li>
<li><p><a class="reference internal" href="#kenning-usage">Kenning usage</a></p></li>
<li><p><a class="reference internal" href="#using-kenning-as-a-library-in-python-scripts">Using Kenning as a library in Python scripts</a></p></li>
<li><p><a class="reference internal" href="#adding-new-implementations">Adding new implementations</a></p></li>
</ul>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Link to this heading">¶</a></h2>
<p>Kenning aims towards providing modular execution blocks for:</p>
<ul class="simple">
<li><p>dataset management,</p></li>
<li><p>model training,</p></li>
<li><p>model optimization and compilation for a given target hardware,</p></li>
<li><p>running models using efficient runtimes on target device,</p></li>
<li><p>model evaluation and performance reports.</p></li>
</ul>
<p>These can be used seamlessly regardless of underlying frameworks for the above-mentioned steps.</p>
<p>Kenning’s aim is not to bring yet another training or compilation framework for deep learning models - there are lots of mature and versatile frameworks that support certain models, training routines, optimization techniques, hardware platforms and other components crucial to the deployment flow.
Still, there is no framework that would support all of the models or target hardware devices - especially the support matrix between compilation frameworks and target hardware is extremely sparse.
This means that any change in the application, especially in hardware, may end up in a necessity to change the entirety or a significant part of the application flow.</p>
<p>Kenning addresses this issue by providing a unified API that focuses on deployment tasks rather than their implementation - the developer decides which implementation should be used for each task, and with Kenning, it is possible to do in a seamless way.
This way, switching to another target platform results, in most cases, in a very small change in the code, instead of reimplementing larger parts of a project.
This is how Kenning can get the most out of the existing Deep Neural Network training and compilation frameworks.</p>
<p>Seamless nature of Kenning also allows developers to quickly evaluate the model on various stages of optimizations and compare them as shown in <a class="reference internal" href="#kenning-usage">Kenning usage</a>.</p>
<h2 id="kenning-installation">Kenning installation<a class="headerlink" href="#kenning-installation" title="Link to this heading">¶</a></h2>
<h3 id="module-installation-with-pip">Module installation with pip<a class="headerlink" href="#module-installation-with-pip" title="Link to this heading">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">NOTE</span></code>: Kenning supports Python up to 3.11.</p>
<p>To install Kenning with its basic dependencies with <code class="docutils literal notranslate"><span class="pre">pip</span></code>, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>git+https://github.com/antmicro/kenning.git
</code></pre></div>
</div>
<p>Since Kenning can support various frameworks, and not all of them are required for users’ particular use cases, some of the requirements are optional.
We can distinguish the following groups of extra requirements:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tensorflow</span></code> - modules for work with TensorFlow models (ONNX conversions, addons, and TensorFlow framework),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch</span></code> - modules for work with PyTorch models,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mxnet</span></code> - modules for work with MXNet models,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nvidia_perf</span></code> - modules for performance measurements for NVIDIA GPUs,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">object_detection</span></code> - modules for work with YOLOv3 object detection and the Open Images Dataset V6 computer vision dataset,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">speech_to_text</span></code> - modules for work with audio samples and speech-to-text models,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">iree</span></code> - modules for IREE compilation and runtime,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tvm</span></code> - modules for Apache TVM compilation and runtime,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">onnxruntime</span></code> - modules for ONNX Runtime,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nni</span></code> - modules for Neural Network Intelligence optimizers,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">docs</span></code> - modules for generating documentation,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">test</span></code> - modules for Kenning framework testing,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">real_time_visualization</span></code> - modules for real time visualization runners,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pipeline_manager</span></code> - modules for communication with visual editor,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">reports</span></code> - modules for generating reports and comparisons,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">uart</span></code> - modules for work with serial ports,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">renode</span></code> - modules for work with Renode,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fuzzy</span></code> - modules for fuzzy search.</p></li>
</ul>
<p>To install the extra requirements, e.g. <code class="docutils literal notranslate"><span class="pre">tensorflow</span></code>, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>sudo<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/antmicro/kenning.git#egg<span class="o">=</span>kenning<span class="o">[</span>tensorflow<span class="o">]</span>
</code></pre></div>
</div>
<p>or, in newer <code class="docutils literal notranslate"><span class="pre">pip</span></code> releases:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;kenning[tensorflow] @ git+https://github.com/antmicro/kenning.git&quot;</span>
</code></pre></div>
</div>
<h3 id="working-directly-with-the-repository">Working directly with the repository<a class="headerlink" href="#working-directly-with-the-repository" title="Link to this heading">¶</a></h3>
<p>For development purposes, and to use additional resources (such as sample scripts), clone the repository with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/antmicro/kenning.git
<span class="nb">cd</span><span class="w"> </span>kenning/
</code></pre></div>
</div>
<p>Then install using:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span><span class="s2">&quot;.[tensorflow,tflite,tvm,reports]&quot;</span>
</code></pre></div>
</div>
<h2 id="kenning-structure">Kenning structure<a class="headerlink" href="#kenning-structure" title="Link to this heading">¶</a></h2>
<p><img alt="" src="_images/class-flow.png" /></p>
<p>The <code class="docutils literal notranslate"><span class="pre">kenning</span></code> module consists of the following submodules:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">core</span></code> - provides interface APIs for datasets, models, optimizers, runtimes, protocols, and data converters</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">datasets</span></code> - provides implementations for datasets</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">modelwrappers</span></code> - provides implementations for models for various problems implemented in various frameworks,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizers</span></code> - provides implementations for compilers and optimizers for deep learning models,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">runtimes</span></code> - provides implementations of runtime on target devices,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">interfaces</span></code> - provides interface classes to group related methods used in Kenning <code class="docutils literal notranslate"><span class="pre">core</span></code> classes,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">protocols</span></code> - provides implementations for communication protocols between host and tested target,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataproviders</span></code> - provides implementations for reading input data from various sources, such as camera, directories or TCP connections,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataconverters</span></code> - provides implementations for data converters for various data types</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">outputcollectors</span></code> - provides implementations for processing outputs from models, i.e. saving results to file, or displaying predictions on screen.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">onnxconverters</span></code> - provides ONNX conversions for a given framework along with a list of models to test the conversion on,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">runners</span></code> - provide implementations for runners that can be used in runtime,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">drawing</span></code> - provides methods for rendering plots for reports,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">resources</span></code> - contains project’s resources, like RST templates, or trained models,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scenarios</span></code> - contains executable scripts for running training, inference, benchmarks and other tests on target devices,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">utils</span></code> - various functions and classes used in all above-mentioned submodules,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tests</span></code> - submodules for framework testing,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pipeline_manager</span></code> - contains tools for integrating with <a class="reference external" href="https://github.com/antmicro/kenning-pipeline-manager">Pipeline Manager visualizer</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cli</span></code> - provides tools and methods for creating CLI tools based on Kenning</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">core</span></code> classes used throughout the entire Kenning framework:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Dataset</span></code> class - performs dataset download, preparation, dataset-specific input preprocessing (i.e. input file opening, normalization), output postprocessing and model evaluation,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ModelWrapper</span></code> class - trains the model, prepares the model, performs model-specific input preprocessing and output postprocessing, runs inference on host using native framework,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Optimizer</span></code> class - optimizes and compiles the model,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Runtime</span></code> class - loads the model, performs inference on compiled model, runs target-specific processing of inputs and outputs, and runs performance benchmarks,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Protocol</span></code> class - implements the communication protocol between the host and the target,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DataProvider</span></code> class - implements data provision from such sources as camera, TCP connection or others for inference,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OutputCollector</span></code> class - implements parsing and utilization of data from inference (such as displaying the visualizations, sending the results to via TCP),</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DataConverter</span></code> class - performs data conversion from dataset-specific format to protocol-specific format and vice versa,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Runner</span></code> class - represents single runtime processing block.</p></li>
</ul>
<h2 id="kenning-usage">Kenning usage<a class="headerlink" href="#kenning-usage" title="Link to this heading">¶</a></h2>
<p>There are several ways to use Kenning:</p>
<ul class="simple">
<li><p>Using executable scripts from the <code class="docutils literal notranslate"><span class="pre">scenarios</span></code> submodule, configurable via JSON files (recommended approach);</p></li>
<li><p>Using executable scripts from the <code class="docutils literal notranslate"><span class="pre">scenarios</span></code> submodule, configurable via command-line arguments;</p></li>
<li><p>Using Kenning as a Python module.</p></li>
</ul>
<p>Kenning scenarios are executable scripts that can be used for:</p>
<ul class="simple">
<li><p>Model training and benchmarking using its native framework (<a class="reference external" href="https://github.com/antmicro/kenning/blob/main/kenning/scenarios/model_training.py"><code class="docutils literal notranslate"><span class="pre">kenning.scenarios.model_training</span></code></a>),</p></li>
<li><p>Model optimization and compilation for target hardware (<a class="reference external" href="https://github.com/antmicro/kenning/blob/main/kenning/scenarios/inference_tester.py"><code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_tester</span></code></a>),</p></li>
<li><p>Model benchmarking on target hardware (<a class="reference external" href="https://github.com/antmicro/kenning/blob/main/kenning/scenarios/inference_tester.py"><code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_tester</span></code></a> and <a class="reference external" href="https://github.com/antmicro/kenning/blob/main/kenning/scenarios/inference_server.py"><code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_server</span></code></a>),</p></li>
<li><p>Rendering performance and quality reports from benchmark data (<a class="reference external" href="https://github.com/antmicro/kenning/blob/main/kenning/scenarios/render_report.py"><code class="docutils literal notranslate"><span class="pre">kenning.scenarios.render_report</span></code></a>),</p></li>
<li><p>and more.</p></li>
</ul>
<p>They are available through the <code class="docutils literal notranslate"><span class="pre">kenning</span></code> executable as subcommands.
To get the current list of subcommands, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>-h
</code></pre></div>
</div>
<p>The available subcommands are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">train</span></code> - trains the given model (<code class="docutils literal notranslate"><span class="pre">kenning.scenarios.model_training</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimize</span></code> - optimizes and compiles the model for a given target device (<code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_tester</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">test</span></code> - runs benchmark and evaluation of the model on the target device (<code class="docutils literal notranslate"><span class="pre">kenning.scenarios.inference_tester</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">report</span></code> - creates Markdown and HTML files summarizing the quality of the model in terms of performance and predictions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">flow</span></code> - runs Kenning-based applications.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">visual-editor</span></code> - runs a graphical interface letting you represent, edit and run optimizations and applications in-browser using <a class="reference external" href="https://github.com/antmicro/kenning-pipeline-manager">Pipeline Manager</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fine-tune-optimizers</span></code> - runs a search for the best optimizations for a given target platform based on selected optimizers, runtimes and models, along with their settings.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">server</span></code> - runs a benchmark and evaluation server on target device.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">info</span></code> - provides information about a given Kenning class.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">list</span></code> - lists available Kenning modules for optimization and runtime.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fuzzy-search</span></code> - searches for class path across Kenning and returns it.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cache</span></code> - manages Kenning cache used for models and datasets.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">completion</span></code> - configures autocompletion feature for Kenning CLI.</p></li>
</ul>
<h3 id="running-kenning">Running Kenning<a class="headerlink" href="#running-kenning" title="Link to this heading">¶</a></h3>
<p>Let’s start off with installing the module and its necessary dependencies:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;kenning[tensorflow,tflite,tvm,pipeline_manager,reports] @ git+https://github.com/antmicro/kenning.git&quot;</span>
</code></pre></div>
</div>
<p>Kenning provides two tools for displaying information about available classes: <code class="docutils literal notranslate"><span class="pre">kenning</span> <span class="pre">list</span></code> and <code class="docutils literal notranslate"><span class="pre">kenning</span> <span class="pre">info</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">kenning</span> <span class="pre">list</span></code> tool lists all available modules used to form optimization and runtime pipelines in Kenning.
Running:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>list
</code></pre></div>
</div>
<p>Should list:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><code><span class="n">Optimizers</span> <span class="p">(</span><span class="ow">in</span> <span class="n">kenning</span><span class="o">.</span><span class="n">optimizers</span><span class="p">):</span>

    <span class="n">kenning</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">nni_pruning</span><span class="o">.</span><span class="n">NNIPruningOptimizer</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">onnx</span><span class="o">.</span><span class="n">ONNXCompiler</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">tensorflow_pruning</span><span class="o">.</span><span class="n">TensorFlowPruningOptimizer</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">model_inserter</span><span class="o">.</span><span class="n">ModelInserter</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">tvm</span><span class="o">.</span><span class="n">TVMCompiler</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">iree</span><span class="o">.</span><span class="n">IREECompiler</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">tensorflow_clustering</span><span class="o">.</span><span class="n">TensorFlowClusteringOptimizer</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">tflite</span><span class="o">.</span><span class="n">TFLiteCompiler</span>

<span class="n">Datasets</span> <span class="p">(</span><span class="ow">in</span> <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="p">):</span>

    <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">pet_dataset</span><span class="o">.</span><span class="n">PetDataset</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">visual_wake_words_dataset</span><span class="o">.</span><span class="n">VisualWakeWordsDataset</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">random_dataset</span><span class="o">.</span><span class="n">RandomizedDetectionSegmentationDataset</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">open_images_dataset</span><span class="o">.</span><span class="n">OpenImagesDatasetV6</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">random_dataset</span><span class="o">.</span><span class="n">RandomizedClassificationDataset</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">common_voice_dataset</span><span class="o">.</span><span class="n">CommonVoiceDataset</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">magic_wand_dataset</span><span class="o">.</span><span class="n">MagicWandDataset</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">coco_dataset</span><span class="o">.</span><span class="n">COCODataset2017</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imagenet_dataset</span><span class="o">.</span><span class="n">ImageNetDataset</span>

<span class="n">Modelwrappers</span> <span class="p">(</span><span class="ow">in</span> <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="p">):</span>

    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">instance_segmentation</span><span class="o">.</span><span class="n">yolact</span><span class="o">.</span><span class="n">YOLACT</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">tflite_magic_wand</span><span class="o">.</span><span class="n">MagicWandModelWrapper</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">pytorch_pet_dataset</span><span class="o">.</span><span class="n">PyTorchPetDatasetMobileNetV2</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">object_detection</span><span class="o">.</span><span class="n">darknet_coco</span><span class="o">.</span><span class="n">TVMDarknetCOCOYOLOV3</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">instance_segmentation</span><span class="o">.</span><span class="n">yolact</span><span class="o">.</span><span class="n">YOLACTWithPostprocessing</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">tensorflow_imagenet</span><span class="o">.</span><span class="n">TensorFlowImageNet</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">tflite_person_detection</span><span class="o">.</span><span class="n">PersonDetectionModelWrapper</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">tensorflow_pet_dataset</span><span class="o">.</span><span class="n">TensorFlowPetDatasetMobileNetV2</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">instance_segmentation</span><span class="o">.</span><span class="n">pytorch_coco</span><span class="o">.</span><span class="n">PyTorchCOCOMaskRCNN</span>
    <span class="n">kenning</span><span class="o">.</span><span class="n">modelwrappers</span><span class="o">.</span><span class="n">object_detection</span><span class="o">.</span><span class="n">yolov4</span><span class="o">.</span><span class="n">ONNXYOLOV4</span>

<span class="o">...</span>
</code></pre></div>
</div>
<p>To list available compilers, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>list<span class="w"> </span>optimizers
</code></pre></div>
</div>
<p>For more verbose information, use the <code class="docutils literal notranslate"><span class="pre">-v</span></code> and <code class="docutils literal notranslate"><span class="pre">-vv</span></code> flags (module dependencies, description, supported formats and more)</p>
<p>The <code class="docutils literal notranslate"><span class="pre">kenning</span> <span class="pre">info</span></code> tool provides more detailed information on a given class, e.g. for:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>info<span class="w"> </span>kenning.optimizers.tflite.TFLiteCompiler
</code></pre></div>
</div>
<p>We should get something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><code><span class="n">Class</span><span class="p">:</span> <span class="n">TFLiteCompiler</span>

    <span class="n">The</span> <span class="n">TFLite</span> <span class="ow">and</span> <span class="n">EdgeTPU</span> <span class="n">compiler</span><span class="o">.</span>

<span class="n">Dependencies</span><span class="p">:</span>
<span class="o">*</span> <span class="n">onnx2tf</span>
<span class="o">*</span> <span class="n">tensorflow</span>
<span class="o">*</span> <span class="n">numpy</span>
<span class="o">*</span> <span class="n">onnx</span>
<span class="o">*</span> <span class="n">tensorflow_model_optimization</span>

<span class="n">Input</span> <span class="n">formats</span><span class="p">:</span>
<span class="o">*</span> <span class="n">keras</span>
<span class="o">*</span> <span class="n">tensorflow</span>
<span class="o">*</span> <span class="n">onnx</span>


<span class="n">Output</span> <span class="n">formats</span><span class="p">:</span>
<span class="o">*</span> <span class="n">tflite</span>


<span class="n">Arguments</span> <span class="n">specification</span><span class="p">:</span>
<span class="o">*</span> <span class="n">model_framework</span>
  <span class="o">*</span> <span class="n">argparse_name</span><span class="p">:</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="n">framework</span>
  <span class="o">*</span> <span class="n">description</span><span class="p">:</span> <span class="n">The</span> <span class="nb">input</span> <span class="nb">type</span> <span class="n">of</span> <span class="n">the</span> <span class="n">model</span><span class="p">,</span> <span class="n">framework</span><span class="o">-</span><span class="n">wise</span>
  <span class="o">*</span> <span class="n">default</span><span class="p">:</span> <span class="n">onnx</span>
  <span class="o">*</span> <span class="n">enum</span>
    <span class="o">*</span> <span class="n">keras</span>
    <span class="o">*</span> <span class="n">tensorflow</span>
    <span class="o">*</span> <span class="n">onnx</span>
<span class="o">*</span> <span class="n">target</span>
  <span class="o">*</span> <span class="n">argparse_name</span><span class="p">:</span> <span class="o">--</span><span class="n">target</span>
  <span class="o">*</span> <span class="n">description</span><span class="p">:</span> <span class="n">The</span> <span class="n">TFLite</span> <span class="n">target</span> <span class="n">device</span> <span class="n">scenario</span>
  <span class="o">*</span> <span class="n">default</span><span class="p">:</span> <span class="n">default</span>
  <span class="o">*</span> <span class="n">enum</span>
    <span class="o">*</span> <span class="n">default</span>
    <span class="o">*</span> <span class="n">int8</span>
    <span class="o">*</span> <span class="n">float16</span>
    <span class="o">*</span> <span class="n">edgetpu</span>
<span class="o">*</span> <span class="n">inference_input_type</span>
  <span class="o">*</span> <span class="n">argparse_name</span><span class="p">:</span> <span class="o">--</span><span class="n">inference</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="nb">type</span>
  <span class="o">*</span> <span class="n">description</span><span class="p">:</span> <span class="n">Data</span> <span class="nb">type</span> <span class="n">of</span> <span class="n">the</span> <span class="nb">input</span> <span class="n">layer</span>
  <span class="o">*</span> <span class="n">default</span><span class="p">:</span> <span class="n">float32</span>
  <span class="o">*</span> <span class="n">enum</span>
    <span class="o">*</span> <span class="n">float32</span>
    <span class="o">*</span> <span class="n">int8</span>
    <span class="o">*</span> <span class="n">uint8</span>
<span class="o">...</span>
</code></pre></div>
</div>
<p>If a certain class does not have necessary dependencies installed, Kenning suggests what modules need to be installed, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><code>This method requires additional dependencies, please use `pip install &quot;kenning[tensorflow]&quot;` to install them.
</code></pre></div>
</div>
<p>The classes described above are used to form optimization and evaluation scenarios in Kenning.
Some of them can also be used to quickly prototype simple applications.</p>
<p>With Kenning, we can combine multiple compilers and optimizers to create a fast and small model, including embedded devices.
The optimization flow can be defined in JSON format, as follows:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;model_wrapper&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.modelwrappers.classification.tensorflow_pet_dataset.TensorFlowPetDatasetMobileNetV2&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tvm-avx2-int8&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning:///models/classification/tensorflow_pet_dataset_mobilenetv2.h5&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;dataset&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.datasets.pet_dataset.PetDataset&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;dataset_root&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/PetDataset&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;optimizers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.optimizers.tflite.TFLiteCompiler&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;target&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int8&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;compiled_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/int8.tflite&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;inference_input_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int8&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;inference_output_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;int8&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;dataset_percentage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.01</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.optimizers.tvm.TVMCompiler&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;target&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;llvm -mcpu=core-avx2&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;conv2d_data_layout&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;NCHW&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;compiled_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/int8_tvm.tar&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;runtime&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;kenning.runtimes.tvm.TVMRuntime&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;parameters&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;save_model_path&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;./build/int8_tvm.tar&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
</div>
<p>The above scenario takes the MobileNetV2 model trained for classification of cat and dog breeds, and passes it to:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">kenning.optimizers.tflite.TFLiteCompiler</span></code> to quantize the weights of the model</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kenning.optimizers.tvm.TVMCompiler</span></code> to create an optimized runtime of the model, utilizing AVX2 vector instructions.</p></li>
</ul>
<p>The optimization of the model, its evaluation and report generation can be run with one command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><code>kenning<span class="w"> </span>optimize<span class="w"> </span><span class="nb">test</span><span class="w"> </span>report<span class="w"> </span>--json-cfg<span class="w"> </span>sample.json<span class="w"> </span>--measurements<span class="w"> </span>out.json<span class="w"> </span>--report-path<span class="w"> </span>report.md<span class="w"> </span>--to-html<span class="w"> </span>report-html
</code></pre></div>
</div>
<p>The generated report can be found in the <code class="docutils literal notranslate"><span class="pre">report-html</span></code> directory.</p>
<h3 id="kenning-tutorials">Kenning tutorials<a class="headerlink" href="#kenning-tutorials" title="Link to this heading">¶</a></h3>
<p>For more examples on Kenning usage, check <a class="reference external" href="https://antmicro.github.io/kenning/kenning-gallery.html">Kenning tutorials</a>.</p>
<h2 id="using-kenning-as-a-library-in-python-scripts">Using Kenning as a library in Python scripts<a class="headerlink" href="#using-kenning-as-a-library-in-python-scripts" title="Link to this heading">¶</a></h2>
<p>Kenning is also a regular Python module - after pip installation it can be used in Python scripts.
The example compilation of the model can look as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kenning.datasets.pet_dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">PetDataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kenning.modelwrappers.classification.tensorflow_pet_dataset</span><span class="w"> </span><span class="kn">import</span> <span class="n">TensorFlowPetDatasetMobileNetV2</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kenning.optimizers.tflite</span><span class="w"> </span><span class="kn">import</span> <span class="n">TFLiteCompiler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kenning.runtimes.tflite</span><span class="w"> </span><span class="kn">import</span> <span class="n">TFLiteRuntime</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kenning.core.measurements</span><span class="w"> </span><span class="kn">import</span> <span class="n">MeasurementsCollector</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">kenning.utils.resource_manager</span><span class="w"> </span><span class="kn">import</span> <span class="n">ResourceURI</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">PetDataset</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./build/pet-dataset/&#39;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TensorFlowPetDatasetMobileNetV2</span><span class="p">(</span>
    <span class="n">model_path</span><span class="o">=</span><span class="n">ResourceURI</span><span class="p">(</span><span class="s1">&#39;kenning:///models/classification/tensorflow_pet_dataset_mobilenetv2.h5&#39;</span><span class="p">),</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_io_specification</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model_path</span><span class="p">)</span>
<span class="n">compiler</span> <span class="o">=</span> <span class="n">TFLiteCompiler</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
    <span class="n">compiled_model_path</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./build/compiled-model.tflite&#39;</span><span class="p">),</span>
    <span class="n">modelframework</span><span class="o">=</span><span class="s1">&#39;keras&#39;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s1">&#39;default&#39;</span><span class="p">,</span>
    <span class="n">inferenceinputtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">,</span>
    <span class="n">inferenceoutputtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span>
<span class="p">)</span>
<span class="n">compiler</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">input_model_path</span><span class="o">=</span><span class="n">ResourceURI</span><span class="p">(</span><span class="s1">&#39;kenning:///models/classification/tensorflow_pet_dataset_mobilenetv2.h5&#39;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>
</div>
<p>The above script downloads the dataset and compiles the model with FP32 inputs and outputs using TensorFlow Lite.</p>
<p>To get a quantized model, replace <code class="docutils literal notranslate"><span class="pre">target</span></code>, <code class="docutils literal notranslate"><span class="pre">inferenceinputtype</span></code> and <code class="docutils literal notranslate"><span class="pre">inferenceoutputtype</span></code> to <code class="docutils literal notranslate"><span class="pre">int8</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span class="n">compiler</span> <span class="o">=</span> <span class="n">TFLiteCompiler</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
    <span class="n">compiled_model_path</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./build/compiled-model.tflite&#39;</span><span class="p">),</span>
    <span class="n">modelframework</span><span class="o">=</span><span class="s1">&#39;keras&#39;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s1">&#39;int8&#39;</span><span class="p">,</span>
    <span class="n">inferenceinputtype</span><span class="o">=</span><span class="s1">&#39;int8&#39;</span><span class="p">,</span>
    <span class="n">inferenceoutputtype</span><span class="o">=</span><span class="s1">&#39;int8&#39;</span><span class="p">,</span>
    <span class="n">dataset_percentage</span><span class="o">=</span><span class="mf">0.3</span>
<span class="p">)</span>
<span class="n">compiler</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">input_model_path</span><span class="o">=</span><span class="n">ResourceURI</span><span class="p">(</span><span class="s1">&#39;kenning:///models/classification/tensorflow_pet_dataset_mobilenetv2.h5&#39;</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div>
</div>
<p>To check how the compiled model is performing, create <code class="docutils literal notranslate"><span class="pre">TFLiteRuntime</span></code> object and run local model evaluation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><code><span class="n">runtime</span> <span class="o">=</span> <span class="n">TFLiteRuntime</span><span class="p">(</span>
    <span class="n">protocol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">model_path</span><span class="o">=</span><span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./build/compiled-model.tflite&#39;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">runtime</span><span class="o">.</span><span class="n">run_locally</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">Path</span><span class="p">(</span><span class="s1">&#39;./build/compiled-model.tflite&#39;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">MeasurementsCollector</span><span class="o">.</span><span class="n">save_measurements</span><span class="p">(</span><span class="s1">&#39;out.json&#39;</span><span class="p">)</span>
</code></pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">runtime.run_locally</span></code> method runs benchmarks of the model on the current device.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">MeasurementsCollector</span></code> class collects all benchmarks’ data for model inference and saves it in JSON format that can be later used to render reports with the <code class="docutils literal notranslate"><span class="pre">kenning.scenarios.render_report</span></code> script.</p>
<p>As it can be observed, all classes accessible from JSON files in these scenarios share their configuration a with the classes in the Python scripts mentioned above.</p>
<h2 id="adding-new-implementations">Adding new implementations<a class="headerlink" href="#adding-new-implementations" title="Link to this heading">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Dataset</span></code>, <code class="docutils literal notranslate"><span class="pre">ModelWrapper</span></code>, <code class="docutils literal notranslate"><span class="pre">Optimizer</span></code>, <code class="docutils literal notranslate"><span class="pre">Protocol</span></code>, <code class="docutils literal notranslate"><span class="pre">Runtime</span></code> and other classes from the <code class="docutils literal notranslate"><span class="pre">kenning.core</span></code> module have dedicated directories for their implementations.
Each method in the base classes that requires implementation raises an <code class="docutils literal notranslate"><span class="pre">NotImplementedError</span></code> exception.
They can be easily implemented or extended, but they need to conform to certain rules, usually described in the source documentation.</p>
<p>For more details and examples on how the Kenning framework can be adjusted and enhanced, follow the <a class="reference external" href="https://antmicro.github.io/kenning/">Kenning documentation</a>.
Implemented methods can be also overridden, if necessary.</p>
<p>Most of the base classes implement <code class="docutils literal notranslate"><span class="pre">form_argparse</span></code> and <code class="docutils literal notranslate"><span class="pre">from_argparse</span></code> methods.
The former creates an argument parser and a group of arguments specific to the base class.
The latter creates an object of the class based on the arguments from argument parser.</p>
<p>Inheriting classes can modify <code class="docutils literal notranslate"><span class="pre">form_argparse</span></code> and <code class="docutils literal notranslate"><span class="pre">from_argparse</span></code> methods to provide better control over their processing, but they should always be based on the results of their base implementations.</p>


  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      2025-09-18
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="introduction.html" class="md-footer__link md-footer__link--prev" aria-label="Previous: Introduction" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Introduction
            </div>
          </div>
        </a>
      
      
        
        <a href="dl-deployment-stack.html" class="md-footer__link md-footer__link--next" aria-label="Next: Deep Learning deployment stack" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Deep Learning deployment stack
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  
  
  <div class="md-footer-meta md-typeset">
    
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-footer-copyright__highlight">
        Copyright &#169; 2020-2025, Antmicro.
        
    </div>
  
      <a href="https://github.com/antmicro/kenning/tree/e1e0e791de694af6c5b6c9d532b0700a742af703">e1e0e791</a>
        @ <a href="https://github.com/antmicro/kenning/tree/main">main</a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://github.com/antmicro" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://twitter.com/antmicro" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
</div>
      
    </div>
    
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": ".", "features": ["toc.integrate"], "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
      
        <script src="_static/sphinx_immaterial_theme.f9d9eeeb247ace16c.min.js?v=8ec58cb5"></script>
    
  </body>
</html>